{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zrZ5WE3J00Sf"
      },
      "outputs": [],
      "source": [
        "\n",
        "import nltk   # Natural Language Tool Kit\n",
        "\n",
        "\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "document = \"The quick brown fox jumped over the lazy dog.   The dog barked in response but the fox was already gone. This was the third time the fox had visited the garden, and the dog was determined to catch him next time.\"\n",
        "\n",
        "tokens = word_tokenize(document)\n",
        "print(tokens)  # punkt is the required package for tokenization.\n",
        "\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "filtered_tokens = [token for token in tokens if token.lower() not in stop_words]\n",
        "print(filtered_tokens)\n",
        "\n",
        "\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "stemmer = PorterStemmer()\n",
        "stemmed_tokens = [stemmer.stem(token) for token in filtered_tokens]\n",
        "print(stemmed_tokens)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import collections\n",
        "\n",
        "# Sample documents\n",
        "documents = {\n",
        "    1: \"This is the first document. It contains some words.\",\n",
        "    2: \"This is the second document. It also contains words.\",\n",
        "    3: \"The third document is different from the first two.\",\n",
        "    4: \"Inverted index is essential for document retrieval.\",\n",
        "}\n",
        "\n",
        "# Function to preprocess and tokenize text\n",
        "def preprocess(text):\n",
        "    text = text.lower()\n",
        "    tokens = re.findall(r'\\w+', text)\n",
        "    return tokens\n",
        "\n",
        "# Create an inverted index\n",
        "def build_inverted_index(documents):\n",
        "    inverted_index = collections.defaultdict(list)\n",
        "    for doc_id, document in documents.items():\n",
        "        tokens = preprocess(document)\n",
        "        for token in tokens:\n",
        "            inverted_index[token].append(doc_id)\n",
        "    return inverted_index\n",
        "\n",
        "# Function to perform document retrieval\n",
        "def retrieve_documents(query, inverted_index):\n",
        "    query_tokens = preprocess(query)\n",
        "    result = set()\n",
        "\n",
        "    # Retrieve documents containing each query token\n",
        "    for token in query_tokens:\n",
        "        if token in inverted_index:\n",
        "            if not result:\n",
        "                result = set(inverted_index[token])\n",
        "            else:\n",
        "                result = result.intersection(inverted_index[token])\n",
        "\n",
        "    return result\n",
        "\n",
        "# Build the inverted index\n",
        "inverted_index = build_inverted_index(documents)\n",
        "\n",
        "# Example queries\n",
        "query1 = input(\"Enter query: \")\n",
        "\n",
        "\n",
        "# Retrieve documents for the queries\n",
        "result1 = retrieve_documents(query1, inverted_index)\n",
        "\n",
        "\n",
        "# Display the results\n",
        "print(\"Query:\", query1)\n",
        "print(\"Matching Documents:\", result1)"
      ],
      "metadata": {
        "id": "TN4eMTKt1b6W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import re\n",
        "\n",
        "# Load the dataset (replace 'emails.csv' with your actual file path)\n",
        "data = pd.read_csv('emails.csv')\n",
        "\n",
        "# Split the data into features (text) and target (spam)\n",
        "X = data['text']\n",
        "y = data['spam']\n",
        "\n",
        "# Convert text to numerical features using TF-IDF vectorization\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_vectorized = vectorizer.fit_transform(X)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_vectorized, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create an SVM classifier\n",
        "svm_classifier = SVC(kernel='linear')\n",
        "\n",
        "# Train the SVM classifier\n",
        "svm_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = svm_classifier.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "# Display classification report\n",
        "class_report = classification_report(y_test, y_pred, target_names=['Not Spam', 'Spam'])\n",
        "print(\"Classification Report:\\n\", class_report)\n",
        "\n",
        "# Define a function to classify email subjects\n",
        "def classify_email(subject):\n",
        "    cleaned_subject = re.sub(r'^Subject:\\s*', '', subject)  # Remove \"Subject:\" prefix\n",
        "    vectorized_subject = vectorizer.transform([cleaned_subject])\n",
        "    prediction = svm_classifier.predict(vectorized_subject)\n",
        "    if prediction[0] == 1:\n",
        "        return \"Spam\"\n",
        "    else:\n",
        "        return \"Not Spam\"\n",
        "\n",
        "# Ask the user to enter an email subject\n",
        "user_input = input(\"Enter an email subject: \")\n",
        "classification_result = classify_email(user_input)\n",
        "print(\"Classification:\", classification_result)\n"
      ],
      "metadata": {
        "id": "ynJD9Wz31fQg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "from scipy.cluster.hierarchy import dendrogram, linkage\n",
        "from sklearn.metrics import silhouette_score\n",
        "\n",
        "# Load the credit card dataset\n",
        "data = pd.read_csv('BankChurners.csv')\n",
        "\n",
        "# Select relevant features\n",
        "X = data[['Customer_Age', 'Dependent_count', 'Months_on_book', 'Total_Relationship_Count', 'Months_Inactive_12_mon']]\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Apply Agglomerative Clustering\n",
        "agg_clustering = AgglomerativeClustering(n_clusters=2)\n",
        "agg_labels = agg_clustering.fit_predict(X_scaled)\n",
        "silhouette_avg = silhouette_score(X_scaled, agg_labels)\n",
        "print(f\"Silhouette Score: {silhouette_avg:.2f}\")\n",
        "\n",
        "# Plot the dendrogram\n",
        "linked = linkage(X_scaled, 'ward')\n",
        "dendrogram(linked, orientation='top', distance_sort='descending', show_leaf_counts=True)\n",
        "plt.show()\n",
        "\n",
        "# Plot the clusters (using 2D projection for visualization)\n",
        "plt.scatter(X_scaled[:, 0], X_scaled[:, 1], c=agg_labels, cmap='rainbow')\n",
        "plt.xlabel('Standardized Customer Age')\n",
        "plt.ylabel('Standardized Dependent Count')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "NjwYSrpj1kLD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def pagerank(graph, damping_factor=0.85, max_iterations=100, tolerance=1e-6):\n",
        "    num_nodes = len(graph)\n",
        "    transition_matrix = np.zeros((num_nodes, num_nodes))\n",
        "\n",
        "    for i, node in enumerate(graph):\n",
        "        num_links = len(graph[node])\n",
        "        for neighbor in graph[node]:\n",
        "            j = list(graph.keys()).index(neighbor)\n",
        "            transition_matrix[j, i] = 1 / num_links\n",
        "\n",
        "    page_rank = np.ones(num_nodes) / num_nodes\n",
        "\n",
        "    for _ in range(max_iterations):\n",
        "        new_page_rank = (1 - damping_factor) / num_nodes + damping_factor * np.dot(transition_matrix, page_rank)\n",
        "\n",
        "        if np.linalg.norm(new_page_rank - page_rank) < tolerance:\n",
        "            break\n",
        "\n",
        "        page_rank = new_page_rank\n",
        "\n",
        "    return page_rank\n",
        "\n",
        "# Define the new example graph\n",
        "graph = {\n",
        "   'A': ['B', 'C','D'],\n",
        "    'B': ['A'],\n",
        "    'C': ['A', 'B'],\n",
        "    'D':['A']\n",
        "}\n",
        "\n",
        "# Calculate PageRank\n",
        "result = pagerank(graph)\n",
        "print(\"PageRank:\", result)"
      ],
      "metadata": {
        "id": "vEi3wTRG1n3d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "data=requests.get(\"https://webscraper.io/test-sites\")\n",
        "\n",
        "data.status_code\n",
        "\n",
        "soup=BeautifulSoup(data.text,'html.parser')\n",
        "\n",
        "soup\n",
        "\n",
        "data=requests.get(\"https://webscraper.io/test-sites/e-commerce/allinone/computers/laptops\")\n",
        "\n",
        "soup1=BeautifulSoup(data.text,\"html.parser\")\n",
        "\n",
        "for data in soup1.find_all(\"div\",class_=\"caption\"):\n",
        "    print(data.get_text())"
      ],
      "metadata": {
        "id": "k9vRABE313Pq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import smtplib\n",
        "import ssl\n",
        "import RPi.GPIO as G\n",
        "import time\n",
        "inp =  35\n",
        "G.setwarnings(False)\n",
        "G.setmode(G.BOARD)\n",
        "G.setup(inp,G.IN)\n",
        "#Your SMTP server\n",
        "host = \"smtp.gmail.com\"\n",
        "port = 465\n",
        "\n",
        "#Your credentials\n",
        "login = \"Sender@mail.com\"\n",
        "password = \"** ** ** **\" #enter your own code\n",
        "\n",
        "#Build your email\n",
        "context = ssl.create_default_context()\n",
        "dest = \"receive@mail.com\"\n",
        "subject = \"Test email Python\"\n",
        "body = \"Paresh Detected\"\n",
        "\n",
        "\n",
        "\n",
        "email = \"Subject: detection\\nTo: receive@mail.com\\nFrom: Sender@mail.com\\nMotion detected\"\n",
        "\n",
        "#Send email\n",
        "while True:\n",
        "    time.sleep(1)\n",
        "    if(G.input(inp)):\n",
        "        print(\"Detected\")\n",
        "        with smtplib.SMTP_SSL(host, port, context=context) as server:\n",
        "            server.login(login, password)\n",
        "            server.sendmail(login, dest, email)\n",
        "            break"
      ],
      "metadata": {
        "id": "FEGRHt1L2Ut7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#include <Keypad.h>\n",
        "\n",
        "const byte ROWS = 4; //four rows\n",
        "const byte COLS = 3; //four columns\n",
        "char keys[ROWS][COLS] = {\n",
        "  {'1', '2', '3'},\n",
        "  {'4', '5', '6'},\n",
        "  {'7', '8', '9'},\n",
        "  {'*', '0', '#'}\n",
        "};\n",
        "byte rowPins[ROWS] = {5, 6, 7, 8}; //connect to the row pinouts of the keypad\n",
        "byte colPins[COLS] = {2, 3, 4}; //connect to the column pinouts of the keypad\n",
        "//Create an object of keypad\n",
        "Keypad keypad = Keypad(makeKeymap(keys), rowPins, colPins, ROWS, COLS);\n",
        "\n",
        "int buzzer = 11; // the pin that the buzzer is attached to\n",
        "int sensor = 10; // the pin that the sensor is attached to\n",
        "int val = 0;\n",
        "unsigned long previousMillis = 0; // will store last time buzzer was updated\n",
        "const long interval = 1000; // interval at which to blink (milliseconds)\n",
        "bool motionDetected = false;\n",
        "bool codeEntered = false;\n",
        "\n",
        "const int codeLength = 4;\n",
        "char correctCode[codeLength] = {'1', '2', '3', '4'};\n",
        "char enteredCode[codeLength];\n",
        "int currentPos = 0;\n",
        "unsigned long startTime = 0;\n",
        "\n",
        "void setup() {\n",
        "  pinMode(buzzer, OUTPUT); // initialize buzzer as an output\n",
        "  pinMode(sensor, INPUT); // initialize sensor as an input\n",
        "  Serial.begin(9600); // initialize serial\n",
        "}\n",
        "\n",
        "void pir() {\n",
        "  val = digitalRead(sensor); // read sensor value\n",
        "  if (val == HIGH) { // check if the sensor is HIGH\n",
        "    if (!motionDetected) {\n",
        "      startTime = millis(); // start the timer\n",
        "      motionDetected = true;\n",
        "      Serial.println(\"Motion detected!\");\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "void loop() {\n",
        "  pir();\n",
        "  char key = keypad.getKey(); // Read the key\n",
        "  // Print if key pressed\n",
        "\n",
        "  if (key) {\n",
        "    Serial.print(\"Key Pressed : \");\n",
        "    Serial.println(key);\n",
        "    if (!codeEntered) {\n",
        "      enteredCode[currentPos] = key;\n",
        "      currentPos++;\n",
        "      if (currentPos == codeLength) {\n",
        "        currentPos = 0;\n",
        "        if (checkCode()) {\n",
        "          Serial.println(\"Code entered correctly!\");\n",
        "          codeEntered = true;\n",
        "          noTone(buzzer); // turn off the buzzer\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "\n",
        "  if (motionDetected && !codeEntered && (millis() - startTime > 10000)) {\n",
        "    tone(buzzer, 1000); // turn on the buzzer at 1000 Hz\n",
        "  }\n",
        "}\n",
        "\n",
        "bool checkCode() {\n",
        "  for (int i = 0; i < codeLength; i++) {\n",
        "    if (enteredCode[i] != correctCode[i]) {\n",
        "      return false;\n",
        "    }\n",
        "  }\n",
        "  return true;\n",
        "}"
      ],
      "metadata": {
        "id": "sm9NjDYJ2a7j"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}